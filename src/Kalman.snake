import pyrat
import pyrat.diff.intfun as intfun
import pyrat.geo.geofun as gf

from snakemake.remote.SFTP import RemoteProvider, RemoteObject

import datetime as dt

import csv

import re

import numpy as np

import pyrat.diff.utils as utils

#Configuration file
configfile: './bisgletscher.json'

#Useful regexes
slc_regex = "(\d{8})_(\d{6})((_[A-B]{3}[l-u]))?"
dt_regex = "(\d{8})_(\d{6})"
dtfmt = "%Y%m%d_%H%M%S"
wildcard_re = "\{\S+\.(?<wildcard_name>\S+)\}"



include: pyrat.rules['geocoding']
include: pyrat.rules['raw_to_slc']


#Working directory
workdir: "../data"

#Subworkflow to get data
subworkflow fetch_data:
    snakefile: "./data/fetch_data.snake"
    workdir: "../data"





#include: pyrat.rules['geocoding']
#include: pyrat.rules['raw_to_slc']

#Parameters of the Itab file
itab_par = config['kalman']

#Initialize stack by checking the files in the folder
files, = glob_wildcards("/mnt/unique_data/2015_GPRI_Dom/raw/{datetime}.tar")
stack = utils.StackHelper(files)


rule all:
    input:
#        'geo/Dom.mli_gc.tif',
        '../reports/figures/20150830_060000_20150830_070000_BBBl.png'







##############################################################################
## Correct squint from existing data
rule correct_squint_in_slc:
    input:
        slc = fetch_data("slc_chan/{dataname}_{chan}{rx}.slc"),
        slc_par = fetch_data("slc_chan/{dataname}_{chan}{rx}.slc.par"),
    output:
        corr =  "slc_desq/{dataname}_{chan}{rx}.slc",
        corr_par = "slc_desq/{dataname}_{chan}{rx}.slc.par"
    params:
        squint_rate = lambda wildcards: config["desquint"]["{chan}_squint_rate".format(chan=wildcards.chan)],
    run:
        slc = gpf.gammaDataset(input.slc_par, input.slc)
        raw_desq = gpf.correct_squint_in_SLC(slc, squint_rate=params.squint_rate)
        raw_desq.tofile(output.corr_par, output.corr)
    wildcard_constraints:
        dataname=dt_regex,
        chan="(A|B){3}",
        rx="(l|u)"



#Convert shape file to tif containing the area to mask
rule shapefile_to_raster:
    input:
        mask = 'geo/swissTLM3D-2016-tlm_gelaendename_Clip.zip',
        dem = 'geo/Dom.tif'
    output:
        mask = 'geo/bisgletscher_mask.tif'
    params:
        feature_name = config['feature_name']
    script:
        'scripts/shapefile_to_raster.py'


#Segment the mask so that it only covers
#the extent covered by DEM
rule segment_mask:
    input:
        mask = 'geo/bisgletscher_mask.tif',
        dem_seg_par = 'geo/' + config['geocoding']['table_name'] + '.dem_seg.par'
    output:
        mask = 'geo/bisgletscher_mask_seg.tif',
        mask_bmp = 'geo/bisgletscher_mask_seg.bmp'
    script:
        'scripts/segment_mask.py'

#Produce a mask of the glacier
rule glacier_mask:
    input:
        mli_ref_par = 'geo/' + config['geocoding']['table_name'] + '.dem_seg.par',
        mask = 'geo/bisgletscher_mask_seg.bmp_fgc'
    output:
        mask = 'geo/bisgletscher_mask.bmp'
    run:
        shell('cp {input.mask} {output.mask}')


#Compute position of reference point and store it in json file
rule reference_coordinate:
    input:
        dem_par = 'geo/' + config['geocoding']['table_name'] + '.dem_seg.par',
        lut = 'geo/' + config['geocoding']['table_name'] + '.gpri_to_dem',
        reference_coord = 'geo/' + config['geocoding']['table_name'] + '.shp',
    output:
        reference_coord = 'geo/' + config['geocoding']['table_name'] + '.json',
    script:
        'scripts/shapefile_to_json.py'



rule mli:
    input:
        slc = 'slc_desq/{slcname}.slc_dec',
        slc_par = 'slc_desq/{slcname}.slc_dec.par'
    output:
        mli = 'mli/{slcname}.mli',
        mli_par = 'mli/{slcname}.mli.par'
    params:
        rlks = config['interferogram']['rlks'],
        azlks = config['interferogram']['azlks'],
    run:
        shell('multi_look {input.slc} {input.slc_par} {output.mli} {output.mli_par} {params.rlks} {params.azlks} - -')


rule cc:
    input:
        ifgram = 'int/{mastername}_{slavename}.int',
        ifgram_par = 'int/{mastername}_{slavename}.int_par',
        mli1  = 'mli/{mastername}.mli',
        mli2  = 'mli/{slavename}.mli',
        mli1_par  = 'mli/{mastername}.mli.par',
    output:
        cc = 'int/{mastername}_{slavename}.cc',
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    params:
        rlks = config['interferogram']['rlks'],
        azlks = config['interferogram']['azlks']
    script:
       './scripts/cc.py'

rule cc_mask:
    output:
        cc_mask = 'diff/{mastername}_{slavename}.cc_mask.bmp',
    input:
        cc =  'int/{mastername}_{slavename}.cc.sm',
        pwr = 'mli/{mastername}.mli',
        mli_par = 'mli/{mastername}.mli.par',
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    params:
        coherence_threshold = config['unwrapping']['coherence_threshold']
    run:
       import pyrat.fileutils.gpri_files as gpf
       wd = gpf.par_to_dict(input.mli_par)['range_samples']
       mask_cmd = "rascc_mask {{input.cc}} {{input.pwr}} {wd} - - - - - {{params.coherence_threshold}} - - - - - - {{output.cc_mask}}".format(wd=wd)
       shell(mask_cmd)

#Invert a mask
rule invert_mask:
    input:
        mask = "{name}.bmp"
    output:
        mask_inv = "{name}_inv.bmp"
    run:
        print(wildcards)
        shell('mask_op {input.mask} {input.mask} {output.mask_inv} 2')

#Convert a layover/shadow map into a bitmap
rule ls_map_bmp:
    input:
        mask = 'geo/' + config['geocoding']['table_name'] + '.sh_map_fgc',
        ref_mli_par = config['geocoding']['ref_mli_par']
    output:
        bmp_mask = "geo/bisgletscher_shadow_layover.bmp"
    script:
        'scripts/layover_shadow_as_bmp.py'

rule glacier_validity_mask:
    input:
        cc_mask = 'diff/{mastername}_{slavename}.cc_mask.bmp',
        glacier_mask = 'geo/bisgletscher_mask.bmp',
    output:
        validity_mask = 'diff/{mastername}_{slavename}.unw_mask.bmp'
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    run:
        shell("mask_op {input.cc_mask} {input.glacier_mask} {output.validity_mask} 0")



rule ifgram:
    input:
        master = 'slc_desq/{mastername}.slc_dec',
        master_par = 'slc_desq/{mastername}.slc_dec.par',
        slave = 'slc_desq/{slavename}.slc_dec',
        slave_par = 'slc_desq/{slavename}.slc_dec.par',
        reference_coord = 'geo/' + config['geocoding']['table_name'] + '.json',
    output:
        int_par = 'int/{mastername}_{slavename}.int_par',
        ifgram = temp('int/{mastername}_{slavename}.int_unref'),
        ifgram_ref = 'int/{mastername}_{slavename}.int',
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    params:
        mli1 = 'mli/{mastername}.mli',
        mli2 = 'mli/{slavename}.mli',
        rlks = config['interferogram']['rlks'],
        azlks = config['interferogram']['azlks'],
        ws = config['interferogram']['reference_region_size'],
    script:
        'analysis/referenced_interferogram.py'


#rule rasmph:
#    output:
#        ras = 'int/{mastername}_{slavename}.int.bmp',
#    input:
#        master_mli = 'mli/{mastername}.mli',
#        int_par = 'int/{mastername}_{slavename}.int_par',
#        ifgram = 'int/{mastername}_{slavename}.int.sm',
#        cc = 'int/{mastername}_{slavename}.cc.sm',
#    wildcard_constraints:
#        mastername=slc_regex,
#        slavename=slc_regex,
#    run:
#        import pyrat.fileutils.gpri_files as gpf
#        wd = gpf.par_to_dict(input.int_par)['interferogram_width']
#        rascmd = "rasmph_pwr {{input.ifgram}} {{input.master_mli}} {wd} - - - - - - - - {{output.ras}} {{input.cc}}".format(wd=wd)
#        shell(rascmd)


#Smooth interferogram
rule adf:
    input:
        ifgram  = 'int/{mastername}_{slavename}.int',
        mli_par = 'mli/{mastername}.mli.par',
    output:
        int_sm = 'int/{mastername}_{slavename}.int.sm',
        cc = 'int/{mastername}_{slavename}.cc.sm',
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    params:
        adf_window =config['interferogram']['adf_window'],
        adf_alpha =config['interferogram']['adf_alpha']
    script:
        './scripts/adf.py'


##Compute unwrapped interferogram
rule unwrap:
    input:
        ifgram = 'int/{mastername}_{slavename}.int.sm',
        int_par = 'int/{mastername}_{slavename}.int_par',
#        mask = "diff/{mastername}_{slavename}.unw_mask.bmp",
        cc_mask = "diff/{mastername}_{slavename}.cc_mask.bmp",
        cc = "int/{mastername}_{slavename}.cc.sm",
        mli_par = 'mli/{mastername}.mli.par',
        reference_coord = 'geo/' + config['geocoding']['table_name'] + '.json',
    output:
        unw = 'diff/{mastername}_{slavename}.unw',
    params:
        mode = config['interferogram']['triangulation_mode']
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    script:
        './scripts/mcf.py'




#Create differential interferogram parameters
rule diff_par:
    output:
        diff_par = 'diff/{mastername}_{slavename}.diff_par'
    input:
        int_par = 'int/{mastername}_{slavename}.int_par'
    wildcard_constraints:
        mastername=slc_regex,
        slavename=slc_regex,
    run:
        par_cmd = "create_diff_par {input.int_par} - {output.diff_par} 0 0"
        shell(par_cmd)
        #add slave and master anmes
        par = gpf.par_to_dict(output.diff_par)
        par.add_parameter('master_mli_par', 'mli/{mastername}.mli.par'.format(**wildcards))
        par.add_parameter('slave_mli_par', 'mli/{slavename}.mli.par'.format(**wildcards))
        gpf.dict_to_par(par, output.diff_par)





#Projects a single corrected interferogram to a map
rule diff_to_map:
    output:
        map = 'outputs/{filename}.diff.pdf'
    input:
        diff = 'diff/{filename}.diff_gc.tif',
        basemap = 'geo/pk25krel_latest_Clip.tif',
        mask = 'geo/swissTLM3D-2016-tlm_gelaendename_Clip',
    script:
        'scripts/overlay_displacement_on_map.py'




rule create_interferogram_stack:
    wildcard_constraints:
        start_dt = dt_regex,
        stop_dt = dt_regex,
    output:
        stack = "diff/{start_dt}_{chan}_{stop_dt}_{chan}.stack"
    input:
        unw = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'diff/{start_dt}_{chan}_{stop_dt}_{chan}.unw',  **itab_par),
        diff_pars = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'int/{start_dt}_{chan}_{stop_dt}_{chan}.int_par',  **itab_par),
        mli_par = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'mli/{start_dt}_{chan}.mli.par',  **itab_par),
        mli = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'mli/{start_dt}_{chan}.mli',  **itab_par),
    script:
        'data/create_interferogram_stack.py'

#Covariance of interferograms
rule unwrapped_covariance:
    output:
#        R = 'cov/{start_dt}_{stop_dt}_{chan}.cov',
        cov_image = '../reports/figures/{start_dt}_{stop_dt}_{chan}.{ext}'
    wildcard_constraints:
        start_dt = dt_regex,
        stop_dt = dt_regex,
    input:
        slc = lambda wildcards: stack.all_patterns_between_dates(wildcards, 'slc_desq/{datetime}_{chan}.slc_dec'),
        slc_par = lambda wildcards: stack.all_patterns_between_dates(wildcards, 'slc_desq/{datetime}_{chan}.slc_dec.par'),
        reference_coord = 'geo/' + config['geocoding']['table_name'] + '.json',
        ref_mli = 'geo/' + config['geocoding']['table_name'] +'.mli',
        ref_mli_par = 'geo/' + config['geocoding']['table_name'] +'.mli.par',
        mask = 'geo/bisgletscher_mask.bmp'
    script:
        'analysis/interferogram_covariance.py'


#Prepare the filter by pickling the filter input, output matrix etc
rule prepare_kalman:
    output:
        z = 'kalman/Kalman_inputs_{start_dt}_{chan}_{i}',
    input:
        unw = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'diff/{start_dt}_{chan}_{stop_dt}_{chan}.unw',  **itab_par),
        diff_pars = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'int/{start_dt}_{chan}_{stop_dt}_{chan}.int_par',  **itab_par),
        mli_par = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'mli/{start_dt}_{chan}.mli.par',  **itab_par),
        mli = lambda wildcards: stack.itab_entries_between_dates(wildcards, 'mli/{start_dt}_{chan}.mli',  **itab_par),
    script:
        'scripts/prepare_kalman.py'



def all_previous(wildcards, pattern, counter_variable):
    wild_copy = dict(wildcards)
    counter = wildcards.get(counter_variable)#extract the counter
    files = []
    for i in range(1, int(counter)):
        wild_copy[counter_variable] = i
        files.append(pattern.format(**wild_copy))
    return files

rule run_kalman:
    output:
        kalman_pickle = 'kalman/kalman_{start_dt}_{chan}_{i}'
    input:
        z = lambda wildcards: all_previous(wildcards, 'kalman/Kalman_inputs_{start_dt}_{chan}_{i}', 'i'),
        ref_mli_par = 'mli/{start_dt}_{chan}.mli.par',
    script:
        'scripts/kalman.py'


